{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e60e3ba",
   "metadata": {},
   "source": [
    "DATA MINING \n",
    "\n",
    "This notebook is designed to guide you through a comparative analysis of three different data mining algorithms: Brute Force, Apriori, and FP-Growth.\n",
    "\n",
    "In the field of data mining, these algorithms are commonly used for frequent itemset mining and association rule generation. Frequent itemset mining is a method for finding itemsets that appear frequently together in a transaction dataset, while association rule generation is a method for discovering interesting relations between variables in large database\n",
    "\n",
    "Throughout this notebook, we will:\n",
    "1. Create transactional databases with items typically found in supermarkets\n",
    "2. Implement the brute force method, Apriori, and FP-Growth algorithms to find frequent itemsets in these databases.\n",
    "3. Generate association rules from the frequent itemsets.\n",
    "4. Compare the results and performance of the three algorithms.\n",
    "algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c7f0924a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary modules\n",
    "import random\n",
    "import csv\n",
    "import os\n",
    "import itertools\n",
    "import pandas as pd\n",
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "from mlxtend.frequent_patterns import apriori, fpgrowth\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d31b4806",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Part 1: Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d4726800",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of items seen in supermarkets\n",
    "items = ['Milk', 'Cheese', 'Yogurt', 'Chicken', 'Beef', 'Bread', 'Chips', 'Cookies', 'Soda', 'Juice']\n",
    "\n",
    "# Create a transaction\n",
    "def transaction(items):\n",
    "    return random.sample(items, random.randint(1, len(items)))\n",
    "\n",
    "# Create a database with the transactions\n",
    "def database(items, transactions, filename):\n",
    "    with open(filename, 'w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        for _ in range(transactions):\n",
    "            writer.writerow(transaction(items))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "828d1698",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Databases have been created successfully.\n"
     ]
    }
   ],
   "source": [
    "# For the initial database\n",
    "database(items, 20, 'database1.csv')\n",
    "\n",
    "# Creating 4 additional, different databases\n",
    "for i in range(2, 6):\n",
    "    database(items, 20, f'database{i}.csv')\n",
    "\n",
    "# Test creation of database\n",
    "print(\"Databases have been created successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7a62356f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Part 2: Algorithm Implementation and Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ffa17412",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Brute Force Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ffdb66c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Association rules generated successfully.\n"
     ]
    }
   ],
   "source": [
    "# Read transactions from a CSV file\n",
    "def read_transactions(filename):\n",
    "    with open(filename, 'r') as file:\n",
    "        reader = csv.reader(file)\n",
    "        return list(reader)\n",
    "\n",
    "# Count the frequency of an itemset in the transactions\n",
    "def count_frequency(itemset, transactions):\n",
    "    return sum(1 for transaction in transactions if set(itemset).issubset(transaction))\n",
    "\n",
    "# Generate all possible itemsets of a certain size\n",
    "def generate_itemsets(items, size):\n",
    "    return list(itertools.combinations(items, size))\n",
    "\n",
    "# Identify frequent itemsets using the brute force method\n",
    "def find_frequent_itemsets(items, transactions, min_frequency):\n",
    "    size = 1\n",
    "    while True:\n",
    "        itemsets = generate_itemsets(items, size)\n",
    "        frequent_itemsets = [itemset for itemset in itemsets if count_frequency(itemset, transactions) >= min_frequency]\n",
    "        if not frequent_itemsets:\n",
    "            break\n",
    "        size += 1\n",
    "    return frequent_itemsets\n",
    "\n",
    "# Generate association rules from the frequent itemsets\n",
    "def generate_association_rules(frequent_itemsets, min_confidence):\n",
    "    rules = []\n",
    "    for itemset in frequent_itemsets:\n",
    "         for i in range(1, len(itemset)):\n",
    "            for antecedent in itertools.combinations(itemset, i):\n",
    "                consequent = tuple(item for item in itemset if item not in antecedent)\n",
    "                confidence = count_frequency(itemset, transactions) / count_frequency(antecedent, transactions)\n",
    "                if confidence >= min_confidence:\n",
    "                    rules.append((antecedent, consequent))\n",
    "    return rules\n",
    "\n",
    "# Read the transactions from the CSV file\n",
    "transactions = read_transactions('database1.csv')\n",
    "\n",
    "# Find the frequent itemsets\n",
    "frequent_itemsets = find_frequent_itemsets(items, transactions, min_frequency=10)\n",
    "\n",
    "# Generate the association rules\n",
    "rules = generate_association_rules(frequent_itemsets, min_confidence=0.5)\n",
    "\n",
    "print(\"Association rules generated successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "347fbcc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Brute Force Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "645b67ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Association rules generated successfully.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Read transactions from a CSV file\n",
    "def read_transactions(filename):\n",
    "    with open(filename, 'r') as file:\n",
    "        reader = csv.reader(file)\n",
    "        return list(reader)\n",
    "\n",
    "# Count the frequency of an itemset in the transactions\n",
    "def count_frequency(itemset, transactions):\n",
    "    return sum(1 for transaction in transactions if set(itemset).issubset(transaction))\n",
    "\n",
    "# Generate all possible itemsets of a certain size\n",
    "def generate_itemsets(items, size):\n",
    "    return list(itertools.combinations(items, size))\n",
    "\n",
    "# Identify frequent itemsets using the brute force method\n",
    "def find_frequent_itemsets(items, transactions, min_frequency):\n",
    "    size = 1\n",
    "    while True:\n",
    "        itemsets = generate_itemsets(items, size)\n",
    "        frequent_itemsets = [itemset for itemset in itemsets if count_frequency(itemset, transactions) >= min_frequency]\n",
    "        if not frequent_itemsets:\n",
    "            break\n",
    "        size += 1\n",
    "    return frequent_itemsets\n",
    "\n",
    "# Generate association rules from the frequent itemsets\n",
    "def generate_association_rules(frequent_itemsets, min_confidence):\n",
    "    rules = []\n",
    "    for itemset in frequent_itemsets:\n",
    "        for i in range(1, len(itemset)):\n",
    "            for antecedent in itertools.combinations(itemset, i):\n",
    "                consequent = tuple(item for item in itemset if item not in antecedent)\n",
    "                confidence = count_frequency(itemset, transactions) / count_frequency(antecedent, transactions)\n",
    "                if confidence >= min_confidence:\n",
    "                    rules.append((antecedent, consequent))\n",
    "    return rules\n",
    "\n",
    "# Read the transactions from the CSV file\n",
    "transactions = read_transactions('database1.csv')\n",
    "\n",
    "# Find the frequent itemsets\n",
    "frequent_itemsets = find_frequent_itemsets(items, transactions, min_frequency=10)\n",
    "\n",
    "# Generate the association rules\n",
    "rules = generate_association_rules(frequent_itemsets, min_confidence=0.5)\n",
    "\n",
    "print(\"Association rules generated successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9e96c10c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Apriori and FP-Growth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "913ee614",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Brute force method took 0.02881908416748047 seconds.\n",
      "Apriori algorithm took 0.018990039825439453 seconds.\n",
      "FP-Growth algorithm took 0.009068012237548828 seconds.\n",
      "Brute force method found 0 frequent itemsets.\n",
      "Apriori algorithm found 1023 frequent itemsets.\n",
      "FP-Growth algorithm found 1023 frequent itemsets.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Read the databases\n",
    "def read_all_databases(database_filenames):\n",
    "    all_transactions = []\n",
    "    for filename in database_filenames:\n",
    "        transactions = read_transactions(filename)\n",
    "        all_transactions.extend(transactions)\n",
    "    return all_transactions\n",
    "\n",
    "# List of database filenames\n",
    "database_filenames = ['database1.csv', 'database2.csv', 'database3.csv', 'database4.csv', 'database5.csv']\n",
    "\n",
    "# Read all the transactions from all databases\n",
    "all_transactions = read_all_databases(database_filenames)\n",
    "\n",
    "# Convert the transactions into a DataFrame\n",
    "te = TransactionEncoder()\n",
    "te_ary = te.fit(all_transactions).transform(all_transactions)\n",
    "df = pd.DataFrame(te_ary, columns=te.columns_)\n",
    "\n",
    "# Minimum support\n",
    "min_support = 0.1\n",
    "\n",
    "# Minimum confidence\n",
    "min_confidence = 0.5\n",
    "\n",
    "# Run the brute force algorithm and measure the time\n",
    "start = time.time()\n",
    "frequent_itemsets_brute_force = find_frequent_itemsets(items, all_transactions, min_support)\n",
    "rules_brute_force = generate_association_rules(frequent_itemsets_brute_force, min_confidence)\n",
    "end = time.time()\n",
    "print(f\"Brute force method took {end - start} seconds.\")\n",
    "\n",
    "# Run the Apriori algorithm and measure the time\n",
    "start = time.time()\n",
    "frequent_itemsets_apriori = apriori(df, min_support=min_support, use_colnames=True)\n",
    "end = time.time()\n",
    "print(f\"Apriori algorithm took {end - start} seconds.\")\n",
    "\n",
    "# Run the FP-Growth algorithm and measure the time\n",
    "start = time.time()\n",
    "frequent_itemsets_fpgrowth = fpgrowth(df, min_support=min_support, use_colnames=True)\n",
    "end = time.time()\n",
    "print(f\"FP-Growth algorithm took {end - start} seconds.\")\n",
    "\n",
    "# Compare the results\n",
    "print(\"Brute force method found {} frequent itemsets.\".format(len(frequent_itemsets_brute_force)))\n",
    "print(\"Apriori algorithm found {} frequent itemsets.\".format(len(frequent_itemsets_apriori)))\n",
    "print(\"FP-Growth algorithm found {} frequent itemsets.\".format(len(frequent_itemsets_fpgrowth)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ed287129",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Performance Analysis & Conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1fe69211",
   "metadata": {},
   "outputs": [],
   "source": [
    "##In conclusion, the project successfully implemented and compared three different algorithms for frequent itemset mining and association rule generation: brute force, Apriori, and FP-Growth. The results showed that both Apriori and FP-Growth produced the same number of frequent itemsets, while the brute force method did not find any. In terms of performance, FP-Growth was the fastest, followed by Apriori, and then the brute force method. Overall, this project demonstrated the practical application and comparison of different algorithms in data mining."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "001478c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
